# CPU缓存和内在屏障

为了提高程序运行的性能，现代CPU在很多方面对程序进行了优化。

例如：CPU高速缓存。尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存（cache）以提高性能。

![image-20220502140755565](https://raw.githubusercontent.com/huxiaoning/img/master/20220502140802.png)



### 多级缓存

- L1 Cache（一级缓存）是CPU第一层高速缓存，分为数据缓存和指令缓存。一般服务器CPU的L1缓存的容量通常在32-4096KB。
- L2 由于L1级高速缓存容量的限制，为了再次提高CPU的运算速度，在CPU外部放置一高速存储器，即二级缓存。
- L3 现在的都是内置的。而它的实际作用即是，L3缓存的应用可以进一步降低内存延迟，同时提升大数据量计算时处理器的性能。具有较大L3缓存的处理器提供更有效的文件系统缓存行为及较短消息和处理器队列长度。一般是多核共享一个L3缓存！



CPU在读取数据时，先在L1中寻找，再从L2寻找，再从L3寻找，然后是内存，再后是外存储器。



### 缓存同步协议

多CPU读取同样的数据进行缓存，进行不同运算之后，最终写入主内存以哪个CPU为准？

在这种高速缓存回写的场景下，有一个缓存一致性协议多数CPU厂商对它进行了实现。

**MESI协议**，它规定每条缓存有个状态位，同时定义了下面四个状态：

- 修改态（Modified）—此cache行已被修改过（脏行），内容已不同于主存，为此cache专有；

- 专有态（Exclusive）—此cache行内容同于主存，但不出现于其它cache中；

- 共享态（Shared）—此cache行内容同于主存，但也出现于其它cache中；

- 无效态（Invalid）-此cache行内容无效（空行）。



  多处理器时，单个CPU对缓存中数据进行了改动，需要通知给其他CPU。

  也就是意味着，CPU处理要控制自己的读写操作，还要监听其他CPU发出的通知，从而保证最终一致。



### CPU性能优化手段 - 运行时指令重排

![image-20220502141810028](https://raw.githubusercontent.com/huxiaoning/img/master/20220502141810.png)

指令重排的场景：当CPU写缓存时发现缓存区块正被其他CPU占用，为了提高CPU处理性能，可能将后面的读缓存命令优先执行。

